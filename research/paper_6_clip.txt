Raising the Bar of AI-generated Image Detection with CLIP
(Abstract and metadata fetched from ArXiv abstract page)

Abstract:
The aim of this work is to explore the potential of pre-trained vision-language models (VLMs) for universal detection of AI-generated images. We develop a lightweight detection strategy based on CLIP features and study its performance in a wide variety of challenging scenarios. We find that, contrary to previous beliefs, it is neither necessary nor convenient to use a large domain-specific dataset for training. On the contrary, by using only a handful of example images from a single generative model, a CLIP-based detector exhibits surprising generalization ability and high robustness across different architectures, including recent commercial tools such as Dalle-3, Midjourney v5, and Firefly. We match the state-of-the-art (SoTA) on in-distribution data and significantly improve upon it in terms of generalization to out-of-distribution data (+6% AUC) and robustness to impaired/laundered data (+13%). Our project is available at this https URL

Subjects: Computer Vision and Pattern Recognition (cs.CV)
Cite as: arXiv:2312.00195 [cs.CV]
(or arXiv:2312.00195v2 [cs.CV] for this version)
https://doi.org/10.48550/arXiv.2312.00195
