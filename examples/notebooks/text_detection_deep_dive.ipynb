{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Detection Deep Dive with Veridex\n",
    "\n",
    "This notebook demonstrates how to use Veridex to detect AI-generated text using various statistical and model-based signals.\n",
    "\n",
    "We will cover:\n",
    "1. **Zlib Entropy**: A lightweight, dependency-free method.\n",
    "2. **Perplexity & Burstiness**: Using language models to measure predictability.\n",
    "3. **Binoculars**: A state-of-the-art zero-shot detection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install veridex[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from veridex.text import ZlibEntropySignal, PerplexitySignal, BinocularsSignal\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Data\n",
    "\n",
    "Let's define some sample texts. One is a classic human text, and the other is a generated-sounding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = \"\"\"\n",
    "The industrial revolution was a period of major mechanization and innovation that began in Great Britain during the mid-18th century and early 19th century and later spread throughout much of the world. The American Industrial Revolution, sometimes referred to as the Second Industrial Revolution, started in the 1870s and continued through World War II.\n",
    "\"\"\"\n",
    "\n",
    "ai_text = \"\"\"\n",
    "The Industrial Revolution marked a significant turning point in history. It was characterized by the transition to new manufacturing processes in Great Britain, continental Europe, and the United States, in the period from about 1760 to sometime between 1820 and 1840. This transition included going from hand production methods to machines.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zlib Entropy Signal\n",
    "\n",
    "This signal uses compression ratios. AI text is often more repetitive or predictable, leading to higher compression (lower entropy ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlib_detector = ZlibEntropySignal()\n",
    "\n",
    "res_human = zlib_detector.detect(human_text)\n",
    "res_ai = zlib_detector.detect(ai_text)\n",
    "\n",
    "print(f\"Human Text Score: {res_human.score:.4f} (Raw: {res_human.metadata['entropy_ratio']:.4f})\")\n",
    "print(f\"AI Text Score:    {res_ai.score:.4f}    (Raw: {res_ai.metadata['entropy_ratio']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perplexity Signal\n",
    "\n",
    "This uses a pre-trained model (default: GPT-2) to calculate the likelihood of the text. Lower perplexity generally indicates AI generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector (downloads model on first run)\n",
    "ppl_detector = PerplexitySignal()\n",
    "\n",
    "res_ppl_human = ppl_detector.detect(human_text)\n",
    "res_ppl_ai = ppl_detector.detect(ai_text)\n",
    "\n",
    "print(\"Human Text Results:\")\n",
    "print(f\"  Score: {res_ppl_human.score:.4f}\")\n",
    "print(f\"  Perplexity: {res_ppl_human.metadata.get('perplexity', 'N/A')}\")\n",
    "\n",
    "print(\"\\nAI Text Results:\")\n",
    "print(f\"  Score: {res_ppl_ai.score:.4f}\")\n",
    "print(f\"  Perplexity: {res_ppl_ai.metadata.get('perplexity', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binoculars Signal\n",
    "\n",
    "Binoculars is a more advanced metric that looks at the ratio of two different perplexity scores. It is considered state-of-the-art for zero-shot detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires downloading larger models and may be slow on CPU\n",
    "try:\n",
    "    binoc_detector = BinocularsSignal()\n",
    "    \n",
    "    res_bin_human = binoc_detector.detect(human_text)\n",
    "    res_bin_ai = binoc_detector.detect(ai_text)\n",
    "    \n",
    "    print(f\"Human Text AI Probability: {res_bin_human.score:.4f}\")\n",
    "    print(f\"AI Text AI Probability:    {res_bin_ai.score:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Binoculars skipped: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
