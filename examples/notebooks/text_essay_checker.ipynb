{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# AI Essay Checker with Veridex\n",
    "\n",
    "This notebook demonstrates how to build an academic integrity tool to detect AI-generated student essays using **Veridex**.\n",
    "\n",
    "We will implement an `EssayChecker` that uses an ensemble of detection signals:\n",
    "1. **Binoculars**: A high-accuracy, zero-shot detector comparing two language models.\n",
    "2. **Perplexity**: A statistical measure of how \"surprising\" the text is to a model.\n",
    "\n",
    "> **Note**: This use case is designed for educational institutions to flag content for review. It should never be used as the sole evidence of misconduct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, we install `veridex` with the text extras. This will install dependencies like `transformers` and `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install veridex[text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 2. Implementation\n",
    "\n",
    "We will create an `EssayChecker` class that encapsulates the logic for analyzing essays. It combines results from multiple signals to provide a confidence score and a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "class_def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from veridex.text import BinocularsSignal, PerplexitySignal\n",
    "\n",
    "class EssayChecker:\n",
    "    \"\"\"Academic integrity checker for student essays\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing detectors... (this may take a moment to download models)\")\n",
    "        # Use high-accuracy detector for academic use\n",
    "        # specific models can be passed to ensure consistent behavior\n",
    "        self.primary_detector = BinocularsSignal(observer_id=\"tiiuae/falcon-7b\", performer_id=\"tiiuae/falcon-7b-instruct\") \n",
    "        # Note: In a real colab with limited RAM, you might use smaller models like:\n",
    "        # self.primary_detector = BinocularsSignal(observer_id=\"distilgpt2\", performer_id=\"gpt2\")\n",
    "        \n",
    "        self.secondary_detector = PerplexitySignal()\n",
    "        print(\"Initialization complete.\")\n",
    "    \n",
    "    def analyze_essay(self, essay_text):\n",
    "        \"\"\"\n",
    "        Analyze student essay for AI generation probability\n",
    "        \"\"\"\n",
    "        # Run both detectors\n",
    "        print(\"Running primary detector (Binoculars)...\")\n",
    "        primary_result = self.primary_detector.run(essay_text)\n",
    "        \n",
    "        print(\"Running secondary detector (Perplexity)...\")\n",
    "        secondary_result = self.secondary_detector.run(essay_text)\n",
    "        \n",
    "        # Ensemble decision (simple average for demonstration)\n",
    "        avg_score = (primary_result.score + secondary_result.score) / 2\n",
    "        avg_confidence = (primary_result.confidence + secondary_result.confidence) / 2\n",
    "        \n",
    "        # Conservative thresholds for academic use\n",
    "        if avg_score > 0.85 and avg_confidence > 0.75:\n",
    "            status = 'LIKELY_AI_GENERATED'\n",
    "            recommendation = 'MANUAL_REVIEW_REQUIRED'\n",
    "        elif avg_score > 0.6:\n",
    "            status = 'UNCERTAIN'\n",
    "            recommendation = 'CONSIDER_INTERVIEW'\n",
    "        else:\n",
    "            status = 'LIKELY_HUMAN_WRITTEN'\n",
    "            recommendation = 'NONE'\n",
    "\n",
    "        return {\n",
    "            'status': status,\n",
    "            'recommendation': recommendation,\n",
    "            'confidence': avg_confidence,\n",
    "            'details': {\n",
    "                'binoculars_score': primary_result.score,\n",
    "                'perplexity_score': secondary_result.score,\n",
    "                'perplexity_val': primary_result.metadata.get('mean_perplexity')\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage",
   "metadata": {},
   "source": [
    "## 3. Analysis\n",
    "\n",
    "Now let's test our checker on some sample texts. We'll verify a human-written sample and an AI-generated sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init_checker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the checker\n",
    "# WARNING: This will download model weights (~500MB - 2GB depending on configuration)\n",
    "checker = EssayChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_essay_human = \"\"\"\n",
    "The nuances of Shakespeare's Hamlet have been debated for centuries, yet the central theme of indecision remains timeless. \n",
    "I remember reading it for the first time in high school and feeling frustrated by his constant delaying. \n",
    "But as I've grown older, I kinda get it? Like, who hasn't been paralyzed by overthinking a big choice?\n",
    "\"\"\"\n",
    "\n",
    "student_essay_ai = \"\"\"\n",
    "Shakespeare's Hamlet serves as a profound exploration of the human condition, specifically the consequences of hesitation. \n",
    "The protagonist's inability to act is often cited as his tragic flaw, or hamartia. \n",
    "Through soliloquies such as \"To be, or not to be,\" Shakespeare illuminates the internal conflict between action and contemplation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(title, text):\n",
    "    print(f\"--- Analyzing: {title} ---\")\n",
    "    try:\n",
    "        result = checker.analyze_essay(text)\n",
    "        print(f\"Status: {result['status']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "        print(f\"Recommendation: {result['recommendation']}\")\n",
    "        print(f\"Scores -> Binoculars: {result['details']['binoculars_score']:.2f}, Perplexity: {result['details']['perplexity_score']:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_report(\"Human Written Sample\", student_essay_human)\n",
    "print_report(\"AI Generated Sample\", student_essay_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By combining multiple signals, we can achieve a more robust detection system. Note that the 'AI' sample above might not be flagged with 100% certainty if it is short or high quality, but the probability scores usually show a clear distinction compared to the human text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
